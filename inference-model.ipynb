{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\n\nfrom tqdm.notebook import tqdm\n\nimport gc; gc.enable()\nfrom IPython.display import clear_output\n\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:54:52.550631Z","iopub.execute_input":"2021-07-23T13:54:52.551005Z","iopub.status.idle":"2021-07-23T13:54:52.558468Z","shell.execute_reply.started":"2021-07-23T13:54:52.550971Z","shell.execute_reply":"2021-07-23T13:54:52.55736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = '../input/commonlitreadabilityprize'\nMODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\nCHECKPOINT_DIR = '../input/clrp-mean-pooling/'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nMAX_LENGTH = 300\nTEST_BATCH_SIZE = 1\nHIDDEN_SIZE = 1024\n\nNUM_FOLDS = 5\nSEEDS = [113, 71]","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:54:52.749877Z","iopub.execute_input":"2021-07-23T13:54:52.750178Z","iopub.status.idle":"2021-07-23T13:54:52.799364Z","shell.execute_reply.started":"2021-07-23T13:54:52.75015Z","shell.execute_reply":"2021-07-23T13:54:52.798381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\ntest.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:54:53.071541Z","iopub.execute_input":"2021-07-23T13:54:53.071874Z","iopub.status.idle":"2021-07-23T13:54:53.110426Z","shell.execute_reply.started":"2021-07-23T13:54:53.071842Z","shell.execute_reply":"2021-07-23T13:54:53.109694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MeanPoolingModel(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(HIDDEN_SIZE, 1)\n        self.loss = nn.MSELoss()\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        \n        outputs = self.model(input_ids, attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        logits = self.linear(mean_embeddings)\n        \n        preds = logits.squeeze(-1).squeeze(-1)\n        \n        if labels is not None:\n            loss = self.loss(preds.view(-1).float(), labels.view(-1).float())\n            return loss\n        else:\n            return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:54:53.218757Z","iopub.execute_input":"2021-07-23T13:54:53.219116Z","iopub.status.idle":"2021-07-23T13:54:53.227087Z","shell.execute_reply.started":"2021-07-23T13:54:53.219088Z","shell.execute_reply":"2021-07-23T13:54:53.226259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_loader(data):\n\n    x_test = data.excerpt.tolist()\n    \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n\n    encoded_test = tokenizer.batch_encode_plus(\n        x_test, \n        add_special_tokens=True, \n        return_attention_mask=True, \n        padding='max_length', \n        truncation=True,\n        max_length=MAX_LENGTH, \n        return_tensors='pt'\n    )\n\n    dataset_test = TensorDataset(\n        encoded_test['input_ids'],\n        encoded_test['attention_mask']\n    )\n\n    dataloader_test = DataLoader(\n        dataset_test,\n        sampler = SequentialSampler(dataset_test),\n        batch_size=TEST_BATCH_SIZE\n    )\n    \n    return dataloader_test\n\ntest_dataloader = get_test_loader(test)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:54:53.399691Z","iopub.execute_input":"2021-07-23T13:54:53.400073Z","iopub.status.idle":"2021-07-23T13:54:53.680246Z","shell.execute_reply.started":"2021-07-23T13:54:53.400043Z","shell.execute_reply":"2021-07-23T13:54:53.67934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions = []\nfor seed in SEEDS:\n    \n    fold_predictions = []\n    \n    for fold in tqdm(range(NUM_FOLDS)):\n        model_path = f\"model_{seed + 1}_{fold + 1}.pth\"\n        \n        print(f\"\\nUsing {model_path}\")\n        \n        model_path = CHECKPOINT_DIR + f\"model_{seed + 1}_{fold + 1}.pth\"\n        model = MeanPoolingModel(MODEL_DIR)\n        model.load_state_dict(torch.load(model_path)) \n        model.to(DEVICE)\n        model.eval()\n\n        predictions = []\n        for batch in test_dataloader:\n\n            batch = tuple(b.to(DEVICE) for b in batch)\n\n            inputs = {'input_ids':      batch[0],\n                      'attention_mask': batch[1],\n                      'labels':         None,\n                     }\n\n     \n            preds = model(**inputs).item()\n            predictions.append(preds)\n            \n        del model \n        gc.collect()\n            \n        fold_predictions.append(predictions)\n    all_predictions.append(np.mean(fold_predictions, axis=0).tolist())\n    \nmodel_predictions = np.mean(all_predictions,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:54:53.681614Z","iopub.execute_input":"2021-07-23T13:54:53.681956Z","iopub.status.idle":"2021-07-23T13:58:25.534576Z","shell.execute_reply.started":"2021-07-23T13:54:53.681921Z","shell.execute_reply":"2021-07-23T13:58:25.532841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nMAX_LEN = 248\nEVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\nROBERTA_PATH = \"/kaggle/input/roberta-base\"\nTOKENIZER_PATH = \"/kaggle/input/roberta-base\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.5363Z","iopub.execute_input":"2021-07-23T13:58:25.536807Z","iopub.status.idle":"2021-07-23T13:58:25.543304Z","shell.execute_reply.started":"2021-07-23T13:58:25.536751Z","shell.execute_reply":"2021-07-23T13:58:25.542488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.545882Z","iopub.execute_input":"2021-07-23T13:58:25.546398Z","iopub.status.idle":"2021-07-23T13:58:25.56847Z","shell.execute_reply.started":"2021-07-23T13:58:25.546341Z","shell.execute_reply":"2021-07-23T13:58:25.567672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.569753Z","iopub.execute_input":"2021-07-23T13:58:25.570173Z","iopub.status.idle":"2021-07-23T13:58:25.754604Z","shell.execute_reply.started":"2021-07-23T13:58:25.570133Z","shell.execute_reply":"2021-07-23T13:58:25.753626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitDataset(Dataset):\n    def __init__(self, df, inference_only=False):\n        super().__init__()\n\n        self.df = df        \n        self.inference_only = inference_only\n        self.text = df.excerpt.tolist()\n        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n    \n        self.encoded = tokenizer.batch_encode_plus(\n            self.text,\n            padding = 'max_length',            \n            max_length = MAX_LEN,\n            truncation = True,\n            return_attention_mask=True\n        )        \n \n\n    def __len__(self):\n        return len(self.df)\n\n    \n    def __getitem__(self, index):        \n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return (input_ids, attention_mask)            \n        else:\n            target = self.target[index]\n            return (input_ids, attention_mask, target)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.756121Z","iopub.execute_input":"2021-07-23T13:58:25.756505Z","iopub.status.idle":"2021-07-23T13:58:25.767426Z","shell.execute_reply.started":"2021-07-23T13:58:25.756465Z","shell.execute_reply":"2021-07-23T13:58:25.766305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})                       \n        \n        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n            \n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )        \n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(768, 1)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n\n        # There are a total of 13 layers of hidden states.\n        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n        # We take the hidden states from the last Roberta layer.\n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n\n        # The number of cells is MAX_LEN.\n        # The size of the hidden state of each cell is 768 (for roberta-base).\n        # In order to condense hidden states of all cells to a context vector,\n        # we compute a weighted average of the hidden states of all cells.\n        # We compute the weight of each cell, using the attention neural network.\n        weights = self.attention(last_layer_hidden_states)\n                \n        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n        # Now we compute context_vector as the weighted average.\n        # context_vector.shape is BATCH_SIZE x 768\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n        \n        # Now we reduce the context vector to the prediction score.\n        return self.regressor(context_vector)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.77106Z","iopub.execute_input":"2021-07-23T13:58:25.771461Z","iopub.status.idle":"2021-07-23T13:58:25.782642Z","shell.execute_reply.started":"2021-07-23T13:58:25.771422Z","shell.execute_reply":"2021-07-23T13:58:25.781663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    \n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n                        \n            pred = model(input_ids, attention_mask)                        \n\n            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n            index += pred.shape[0]\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.784548Z","iopub.execute_input":"2021-07-23T13:58:25.784976Z","iopub.status.idle":"2021-07-23T13:58:25.795227Z","shell.execute_reply.started":"2021-07-23T13:58:25.784935Z","shell.execute_reply":"2021-07-23T13:58:25.794415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = LitDataset(test_df, inference_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.79636Z","iopub.execute_input":"2021-07-23T13:58:25.796691Z","iopub.status.idle":"2021-07-23T13:58:25.810813Z","shell.execute_reply.started":"2021-07-23T13:58:25.796656Z","shell.execute_reply":"2021-07-23T13:58:25.809998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_MODELS = 5\n\nall_predictions = np.zeros((NUM_MODELS, len(test_df)))\n\n\n\ntest_dataset = LitDataset(test_df, inference_only=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor model_index in range(NUM_MODELS):            \n    model_path = f\"../input/roberta-training/model_{model_index + 1}.pth\"\n    print(f\"\\nUsing {model_path}\")\n                        \n    model = LitModel()\n    model.load_state_dict(torch.load(model_path, map_location=DEVICE))    \n    model.to(DEVICE)\n        \n    all_predictions[model_index] = predict(model, test_loader)\n            \n    del model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:25.812593Z","iopub.execute_input":"2021-07-23T13:58:25.813096Z","iopub.status.idle":"2021-07-23T13:58:56.181818Z","shell.execute_reply.started":"2021-07-23T13:58:25.812976Z","shell.execute_reply":"2021-07-23T13:58:56.18065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1_predictions = all_predictions.mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:56.183807Z","iopub.execute_input":"2021-07-23T13:58:56.184199Z","iopub.status.idle":"2021-07-23T13:58:56.190873Z","shell.execute_reply.started":"2021-07-23T13:58:56.184158Z","shell.execute_reply":"2021-07-23T13:58:56.189678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_predictions*0.45 + 0.55*model1_predictions","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:56.192532Z","iopub.execute_input":"2021-07-23T13:58:56.193225Z","iopub.status.idle":"2021-07-23T13:58:56.19991Z","shell.execute_reply.started":"2021-07-23T13:58:56.193183Z","shell.execute_reply":"2021-07-23T13:58:56.198714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\nsubmit.target = predictions\nsubmit","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:56.201881Z","iopub.execute_input":"2021-07-23T13:58:56.202331Z","iopub.status.idle":"2021-07-23T13:58:56.223643Z","shell.execute_reply.started":"2021-07-23T13:58:56.202293Z","shell.execute_reply":"2021-07-23T13:58:56.222363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T13:58:56.225482Z","iopub.execute_input":"2021-07-23T13:58:56.225923Z","iopub.status.idle":"2021-07-23T13:58:56.23317Z","shell.execute_reply.started":"2021-07-23T13:58:56.225879Z","shell.execute_reply":"2021-07-23T13:58:56.231724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}